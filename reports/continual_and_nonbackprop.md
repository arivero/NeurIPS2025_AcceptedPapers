# Targeted Paper List

## Continual or Continuous Learning

- **Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge** (Accept (poster)) — Agentic search such as Deep Research systems—where large language models autonomously browse the web, synthesize information, and return citation-backed answers—represents a major shift in how users interact with web-… [OpenReview](https://openreview.net/forum?id=AUaW6DS9si)
- **COOPERA: Continual Open-Ended Human-Robot Assistance** (Accept (spotlight)) — To understand and collaborate with humans, robots must account for individual human traits, habits, and activities over time. However, most robotic assistants lack these abilities, as they primarily focus on predefined… [OpenReview](https://openreview.net/forum?id=wOSZVnYH5w)
- **Curriculum Model Merging: Harmonizing Expert Chemical LLMs for Enhanced Cross-Task Generalization** (Accept (poster)) — The emergence of large language models (LLMs) prompts fine-tuning foundation LLMs to solve real-world chemical problems. However, these chemical LLMs are tailored to specific task formats or narrow content domains,… [OpenReview](https://openreview.net/forum?id=m7Aw57oI3U)
- **Self-Evolving Pseudo-Rehearsal for Catastrophic Forgetting with Task Similarity in LLMs** (Accept (poster)) — Continual learning for large language models (LLMs) demands a precise balance between $\textbf{plasticity}$ - the ability to absorb new tasks - and $\textbf{stability}$ - the preservation of previously learned… [OpenReview](https://openreview.net/forum?id=jR1lvwexLt)
- **Mint: A Simple Test-Time Adaptation of Vision-Language Models against Common Corruptions** (Accept (poster)) — Pretrained vision-language models such as CLIP achieve strong zero-shot generalization but remain vulnerable to distribution shifts caused by input corruptions. In this work, we investigate how corruptions affect CLIP’s… [OpenReview](https://openreview.net/forum?id=yJpBVE4vfo)
- **Shapley-Coop: Credit Assignment for Emergent Cooperation in Self-Interested LLM Agents** (Accept (poster)) — Large Language Models (LLMs) are increasingly deployed as autonomous agents in multi-agent systems, and promising coordination has been demonstrated in handling complex tasks under predefined roles and scripted… [OpenReview](https://openreview.net/forum?id=HnJ1UkuJXS)
- **Scaling Up Parameter Generation: A Recurrent Diffusion Approach** (Accept (poster)) — Parameter generation has long struggled to match the scale of today's large vision and language models, curbing its broader utility. In this paper, we introduce Recurrent Diffusion for Large-Scale Parameter Generation… [OpenReview](https://openreview.net/forum?id=65llKR17s4)
- **Lifelong Safety Alignment for Language Models** (Accept (poster)) — LLMs have made impressive progress, but their growing capabilities also expose them to highly flexible jailbreaking attacks designed to bypass safety alignment. While many existing defenses focus on known types of… [OpenReview](https://openreview.net/forum?id=9YkEcAqiIK)
- **Gradient-Guided Epsilon Constraint Method for Online Continual Learning** (Accept (poster)) — Online Continual Learning (OCL) requires models to learn sequentially from data streams with limited memory. Rehearsal-based methods, particularly Experience Replay (ER), are commonly used in OCL scenarios. This paper… [OpenReview](https://openreview.net/forum?id=MuhYHqLDZT)
- **Confusion-Driven Self-Supervised Progressively Weighted Ensemble Learning for Non-Exemplar Class Incremental Learning** (Accept (poster)) — Non-exemplar class incremental learning (NECIL) aims to continuously assimilate new knowledge while retaining previously acquired knowledge in scenarios where prior examples are unavailable. A prevalent strategy within… [OpenReview](https://openreview.net/forum?id=yflq8Bhjrw)
- **Gradient Descent as Loss Landscape Navigation: a Normative Framework for Deriving Learning Rules** (Accept (poster)) — Learning rules—prescriptions for updating model parameters to improve performance—are typically assumed rather than derived. Why do some learning rules work better than others, and under what assumptions can a given… [OpenReview](https://openreview.net/forum?id=oMi4uyNOlL)
- **Deep RL Needs Deep Behavior Analysis: Exploring Implicit Planning by Model-Free Agents in Open-Ended Environments** (Accept (poster)) — Understanding the behavior of deep reinforcement learning (DRL) agents—particularly as task and agent sophistication increase—requires more than simple comparison of reward curves, yet standard methods for behavioral… [OpenReview](https://openreview.net/forum?id=QD06Qv7O0P)
- **MINGLE: Mixtures of Null-Space Gated Low-Rank Experts for Test-Time Continual Model Merging** (Accept (poster)) — Continual model merging integrates independently fine-tuned models sequentially without access to original training data, providing a scalable and efficient solution to continual learning. However, current methods still… [OpenReview](https://openreview.net/forum?id=8DCyv8x58O)
- **Policy Compatible Skill Incremental Learning via Lazy Learning Interface** (Accept (spotlight)) — Skill Incremental Learning (SIL) is the process by which an embodied agent expands and refines its skill set over time by leveraging experience gained through interaction with its environment or by the integration of… [OpenReview](https://openreview.net/forum?id=xmYT1JqVpj)
- **Gated Integration of Low-Rank Adaptation for  Continual Learning of Language Models** (Accept (poster)) — Continual learning (CL), which requires the model to learn multiple tasks sequentially, is crucial for language models (LMs). Recently, low-rank adaptation (LoRA), one of the most representative parameter-efficient… [OpenReview](https://openreview.net/forum?id=lVV7F0piDK)
- **The Dual Nature of Plasticity Loss in Deep Continual Learning: Dissection and Mitigation** (Accept (poster)) — Loss of plasticity (LoP) is the primary cause of cognitive decline in normal aging brains next to cell loss.Recent works show that similar LoP also plagues neural networks during deep continual learning (DCL). While it… [OpenReview](https://openreview.net/forum?id=vvD0Bre3Dk)
- **MM-OPERA: Benchmarking Open-ended Association Reasoning for Large Vision-Language Models** (Accept (poster)) — Large Vision-Language Models (LVLMs) have exhibited remarkable progress. However, deficiencies remain compared to human intelligence, such as hallucination and shallow pattern matching. In this work, we aim to evaluate… [OpenReview](https://openreview.net/forum?id=6BpKATZQd8)
- **Mix Data or Merge Models? Balancing the Helpfulness, Honesty, and Harmlessness of Large Language Model via Model Merging** (Accept (poster)) — Achieving balanced alignment of large language models (LLMs) in terms of Helpfulness, Honesty, and Harmlessness (3H optimization) constitutes a cornerstone of responsible AI. Existing methods like data mixture… [OpenReview](https://openreview.net/forum?id=SNJhYhO3a9)
- **Lifelong Test-Time Adaptation via Learning in Tracked Low-Dimensional Subspace** (Accept (poster)) — Test-time adaptation (TTA) aims to adapt a source model to a target domain using only test data. Existing methods predominantly rely on unsupervised entropy minimization or its variants, which suffer from degeneration,… [OpenReview](https://openreview.net/forum?id=NFvAa2hNzH)
- **Masked Transformers with Test-Time Adaptation for Speech Neuroprostheses** (Accept (poster)) — Speech neuroprostheses offer a path to restore communication in patients with severe paralysis by decoding speech directly from neural activity. To function seamlessly, speech neuroprostheses should ideally be (1)… [OpenReview](https://openreview.net/forum?id=0U7D9AFiZ0)
- **GraphKeeper: Graph Domain-Incremental Learning via Knowledge Disentanglement and Preservation** (Accept (poster)) — Graph incremental learning (GIL), which continuously updates graph models by sequential knowledge acquisition, has garnered significant interest recently. However, existing GIL approaches focus on task-incremental and… [OpenReview](https://openreview.net/forum?id=AIlaBrwwJO)
- **Activation-Guided Consensus Merging for Large Language Models** (Accept (poster)) — Recent research has increasingly focused on reconciling the reasoning capabilities of System 2 with the efficiency of System 1. While existing training-based and prompt-based approaches face significant challenges in… [OpenReview](https://openreview.net/forum?id=ayzWTxb9ZD)
- **Tru-POMDP: Task Planning Under Uncertainty via Tree of Hypotheses and Open-Ended POMDPs** (Accept (poster)) — Task planning under uncertainty is essential for home-service robots operating in the real world. Tasks involve ambiguous human instructions, hidden or unknown object locations, and open-vocabulary object types, leading… [OpenReview](https://openreview.net/forum?id=1GIQOV3NAj)
- **DP-LLM: Runtime Model Adaptation with Dynamic Layer-wise Precision Assignment** (Accept (poster)) — How can we effectively handle queries for on-device large language models (LLMs) with varying runtime constraints, such as latency and accuracy? Multi-scale quantization addresses this challenge by enabling memory-… [OpenReview](https://openreview.net/forum?id=ppKDXf55lY)
- **Continuous Subspace Optimization for Continual Learning** (Accept (poster)) — Continual learning aims to learn multiple tasks sequentially while preserving prior knowledge, but faces the challenge of catastrophic forgetting when acquiring new knowledge. Recently, approaches leveraging pre-trained… [OpenReview](https://openreview.net/forum?id=iLYV4iIC0c)
- **Diffusion-Classifier Synergy: Reward-Aligned Learning via Mutual Boosting Loop for FSCIL** (Accept (poster)) — Few-Shot Class-Incremental Learning (FSCIL) challenges models to sequentially learn new classes from minimal examples without forgetting prior knowledge, a task complicated by the stability-plasticity dilemma and data… [OpenReview](https://openreview.net/forum?id=ub5QBBQ47S)
- **OOD-Barrier: Build a Middle-Barrier for Open-Set Single-Image Test Time Adaptation via Vision Language Models** (Accept (poster)) — In real-world environments, a well-designed model must be capable of handling dynamically evolving distributions, where both in-distribution (ID) and out-of-distribution (OOD) samples appear unpredictably and… [OpenReview](https://openreview.net/forum?id=GUPx2otaKL)
- **VRAG-RL: Empower Vision-Perception-Based RAG for Visually Rich Information Understanding via Iterative Reasoning with Reinforcement Learning** (Accept (poster)) — Effectively retrieving, reasoning and understanding visually rich information remains a challenge for traditional Retrieval-Augmented Generation (RAG) methods. On the one hand, traditional text-based methods cannot… [OpenReview](https://openreview.net/forum?id=EeAHhNwXPV)
- **Among Us: A Sandbox for Measuring and Detecting Agentic Deception** (Accept (spotlight)) — Prior studies on deception in language-based AI agents typically assess whether the agent produces a false statement about a topic, or makes a binary choice prompted by a goal, rather than allowing open-ended deceptive… [OpenReview](https://openreview.net/forum?id=XP3v1THxsq)
- **Latent Principle Discovery for Language Model Self-Improvement** (Accept (poster)) — When language model (LM) users aim to improve the quality of its generations, it is crucial to specify concrete behavioral attributes that the model should strive to reflect. However, curating such principles across… [OpenReview](https://openreview.net/forum?id=T3ReIjtbYy)
- **C${}^2$Prompt: Class-aware Client Knowledge Interaction for Federated Continual Learning** (Accept (poster)) — Federated continual learning (FCL) tackles scenarios of learning from continuously emerging task data across distributed clients, where the key challenge lies in addressing both temporal forgetting over time and spatial… [OpenReview](https://openreview.net/forum?id=pKqLOmF3Lf)
- **ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in Large Language Models** (Accept (poster)) — Recent advances in reasoning-centric language models have highlighted reinforcement learning (RL) as a promising method for aligning models with verifiable rewards. However, it remains contentious whether RL truly… [OpenReview](https://openreview.net/forum?id=YPsJha5HXQ)
- **Learning Multi-Source and Robust Representations for Continual Learning** (Accept (poster)) — Plasticity and stability denote the ability to assimilate new tasks while preserving previously acquired knowledge, representing two important concepts in continual learning. Recent research addresses stability by… [OpenReview](https://openreview.net/forum?id=24vq7c6MpR)
- **Dynamic Siamese Expansion Framework for Improving Robustness in Online Continual Learning** (Accept (poster)) — Continual learning requires the model to continually capture novel information without forgetting prior knowledge. Nonetheless, existing studies predominantly address the catastrophic forgetting, often neglecting… [OpenReview](https://openreview.net/forum?id=M1OqlaNrw7)
- **Learning Expandable and Adaptable Representations for Continual Learning** (Accept (poster)) — Extant studies predominantly address catastrophic forgetting within a simplified continual learning paradigm, typically confined to a singular data domain. Conversely, real-world applications frequently encompass… [OpenReview](https://openreview.net/forum?id=uXKgVqYTJ2)
- **Continual Model Merging without Data: Dual Projections for Balancing Stability and Plasticity** (Accept (poster)) — Model merging integrates multiple expert models with diverse capabilities into a unified framework, facilitating collaborative learning. However, most existing methods assume simultaneous access to all models, which is… [OpenReview](https://openreview.net/forum?id=zD5cUX67b9)
- **Merging on the Fly Without Retraining: A Sequential Approach to Scalable Continual Model Merging** (Accept (poster)) — Deep model merging represents an emerging research direction that combines multiple fine-tuned models to harness their specialized capabilities across different tasks and domains. Current model merging techniques focus… [OpenReview](https://openreview.net/forum?id=rdGMyTPhui)
- **Continual Knowledge Adaptation for Reinforcement Learning** (Accept (poster)) — Reinforcement Learning enables agents to learn optimal behaviors through interactions with environments. However, real-world environments are typically non-stationary, requiring agents to continuously adapt to new tasks… [OpenReview](https://openreview.net/forum?id=QRlVickNdN)
- **SNAP: Low-Latency Test-Time Adaptation with Sparse Updates** (Accept (poster)) — Test-Time Adaptation (TTA) adjusts models using unlabeled test data to handle dynamic distribution shifts. However, existing methods rely on frequent adaptation and high computational cost, making them unsuitable for… [OpenReview](https://openreview.net/forum?id=8JwMjKDppz)
- **PANDA: Towards Generalist Video Anomaly Detection via Detective-like Agent** (Accept (poster)) — Video anomaly detection (VAD) is a critical yet challenging task due to the complex and diverse nature of real-world scenarios. Previous methods typically rely on domain-specific training data and manual adjustments… [OpenReview](https://openreview.net/forum?id=qE3knKF1rz)
- **FAVOR-Bench: A Comprehensive Benchmark for Fine-Grained Video Motion Understanding** (Accept (poster)) — Multimodal Large Language Models (MLLMs) have shown impressive video content understanding capabilities but struggle with fine-grained motion comprehension. To comprehensively assess the motion understanding ability of… [OpenReview](https://openreview.net/forum?id=DCxsuBXHvx)
- **OVS Meets Continual Learning: Towards Sustainable Open-Vocabulary Segmentation** (Accept (poster)) — Open-Vocabulary Segmentation (OVS) aims to segment classes that are not present in the training dataset. However, most existing studies assume that the training data is fixed in advance, overlooking more practical… [OpenReview](https://openreview.net/forum?id=y8Hv7EdcRF)
- **Learning Interestingness in Automated Mathematical Theory Formation** (Accept (spotlight)) — We take two key steps in automating the open-ended discovery of new mathematical theories, a grand challenge in artificial intelligence. First, we introduce Fermat, a reinforcement learning (RL) environment that models… [OpenReview](https://openreview.net/forum?id=RespmwOoCH)
- **Partner Modelling Emerges in Recurrent Agents (But Only When It Matters)** (Accept (poster)) — Humans are remarkably adept at collaboration, able to infer the strengths and weaknesses of new partners in order to work successfully towards shared goals. To build AI systems with this capability, we must first… [OpenReview](https://openreview.net/forum?id=WydxWM2xNb)
- **Model Inversion with Layer-Specific Modeling and Alignment for Data-Free Continual Learning** (Accept (poster)) — Continual learning (CL) aims to adapt a model to a sequence of tasks while maintaining performance on previously seen ones. Despite their effectiveness in mitigating forgetting, data storage and replay are often… [OpenReview](https://openreview.net/forum?id=yruGxKsZyH)
- **$\mathcal{X}^2$-DFD: A framework for e$\mathcal{X}$plainable and e$\mathcal{X}$tendable Deepfake Detection** (Accept (poster)) — This paper proposes **$\mathcal{X}^2$-DFD**, an **e$\mathcal{X}$plainable** and **e$\mathcal{X}$tendable** framework based on multimodal large-language models (MLLMs) for deepfake detection, consisting of three key… [OpenReview](https://openreview.net/forum?id=tAKbMv3sf7)
- **Can Agent Fix Agent Issues?** (Accept (poster)) — LLM-based agent systems are emerging as a new software paradigm and have been widely adopted across diverse domains such as medicine, robotics, and programming. However, maintaining these systems requires substantial… [OpenReview](https://openreview.net/forum?id=N9HLe9iPhj)
- **Continual Multimodal Contrastive Learning** (Accept (poster)) — Multimodal Contrastive Learning (MCL) advances in aligning different modalities and generating multimodal representations in a joint space. By leveraging contrastive learning across diverse modalities, large-scale… [OpenReview](https://openreview.net/forum?id=juROy8NYRD)
- **Absolute Zero: Reinforced Self-play Reasoning with Zero Data** (Accept (spotlight)) — Reinforcement learning with verifiable rewards (RLVR) has shown promise in enhancing the reasoning capabilities of large language models by learning directly from rule-based outcome rewards. Recent RLVR works that… [OpenReview](https://openreview.net/forum?id=neZSGqhxDa)
- **Mixture of Noise for Pre-Trained Model-Based Class-Incremental Learning** (Accept (poster)) — Class Incremental Learning (CIL) aims to continuously learn new categories while retaining the knowledge of old ones. Pre-trained models (PTMs) show promising capabilities in CIL. However, existing approaches that apply… [OpenReview](https://openreview.net/forum?id=wI6oHXeTR8)
- **Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?** (Accept (oral)) — Reinforcement Learning with Verifiable Rewards (RLVR) has recently demonstrated notable success in enhancing the reasoning performance of large language models (LLMs), particularly in mathematics and programming tasks.… [OpenReview](https://openreview.net/forum?id=4OsgYD7em5)
- **Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?** (Accept (oral)) — Reinforcement Learning with Verifiable Rewards (RLVR) has recently demonstrated notable success in enhancing the reasoning performance of large language models (LLMs), particularly in mathematics and programming tasks.… [OpenReview](https://openreview.net/forum?id=2025-Oral--6514-a0cd0729)
- **A Minimalistic Unified Framework for Incremental Learning across Image Restoration Tasks** (Accept (poster)) — Existing research in low-level vision has shifted its focus from "one-by-one" task-specific methods to "all-in-one" multi-task unified architectures. However, current all-in-one image restoration approaches primarily… [OpenReview](https://openreview.net/forum?id=MBQZwQ6vFd)
- **Test-Time Adaptive Object Detection with Foundation Model** (Accept (poster)) — In recent years, test-time adaptive object detection has attracted increasing attention due to its unique advantages in online domain adaptation, which aligns more closely with real-world application scenarios. However,… [OpenReview](https://openreview.net/forum?id=MO4U4mg0oT)
- **FLUX: Efficient Descriptor-Driven Clustered Federated Learning under Arbitrary Distribution Shifts** (Accept (poster)) — Federated Learning (FL) enables collaborative model training across multiple clients while preserving data privacy. Traditional FL methods often use a global model to fit all clients, assuming that clients' data are… [OpenReview](https://openreview.net/forum?id=ntOPGmlrkV)
- **Artificial Hivemind: The Open-Ended Homogeneity of Language Models (and Beyond)** (Accept (oral)) — Language models (LMs) often struggle to generate diverse, human-like creative content, raising concerns about the long-term homogenization of human thought through repeated exposure to similar outputs. Yet, scalable… [OpenReview](https://openreview.net/forum?id=saDOrrnNTz)
- **Artificial Hivemind: The Open-Ended Homogeneity of Language Models (and Beyond)** (Accept (oral)) — Language models (LMs) often struggle to generate diverse, human-like creative content, raising concerns about the long-term homogenization of human thought through repeated exposure to similar outputs. Yet, scalable… [OpenReview](https://openreview.net/forum?id=2025-Oral--2331-48b687c8)
- **Online Functional Tensor Decomposition via Continual Learning for Streaming Data Completion** (Accept (spotlight)) — Online tensor decompositions are powerful and proven techniques that address the challenges in processing high-velocity streaming tensor data, such as traffic flow and weather system. The main aim of this work is to… [OpenReview](https://openreview.net/forum?id=RPuTB28HsK)
- **MM-Agent: LLM as Agents for Real-world Mathematical Modeling Problem** (Accept (poster)) — Mathematical modeling is a cornerstone of scientific discovery and engineering practice, enabling the translation of real-world problems into formal systems across domains such as physics, biology, and economics. Unlike… [OpenReview](https://openreview.net/forum?id=o8n5oNDsiq)
- **Conformal Prediction with Query Oracle: A Missing Mass Perspective for Uncertainty Quantification in Generative Models** (Accept (poster)) — Uncertainty quantification (UQ) is essential for safe deployment of generative AI models such as large language models (LLMs), especially in high-stakes applications. Conformal prediction (CP) offers a principled UQ… [OpenReview](https://openreview.net/forum?id=KoVKLxn3Nb)
- **EVAAA: A Virtual Environment Platform for Essential Variables in Autonomous and Adaptive Agents** (Accept (poster)) — Reinforcement learning (RL) agents have demonstrated strong performance in structured environments, yet they continue to struggle in real-world settings where goals are ambiguous, conditions change dynamically, and… [OpenReview](https://openreview.net/forum?id=aQaRZ8wj67)
- **Factorio Learning Environment** (Accept (poster)) — Large Language Models (LLMs) are rapidly saturating existing benchmarks, necessitating new open-ended evaluations. We introduce the Factorio Learning Environment (FLE), based on the game of Factorio, that tests agents… [OpenReview](https://openreview.net/forum?id=652Q6jBFMZ)
- **Overcoming Long-Context Limitations of State-Space Models via Hybrid Sparse Attention** (Accept (poster)) — Long-context modeling is a fundamental challenge in natural language processing (NLP) with numerous practical applications. State-space models (SSMs) have gained attention as a promising alternative to Transformers,… [OpenReview](https://openreview.net/forum?id=XsNi2STaj0)
- **Quadratic Coreset Selection: Certifying and Reconciling Sequence and Token Mining for Efficient Instruction Tuning** (Accept (poster)) — Instruction-Tuning (IT) was recently found the impressive data efficiency in post-training large language models (LLMs). While the pursuit of efficiency predominantly focuses on sequence-level curation, often… [OpenReview](https://openreview.net/forum?id=btZm6DUaDO)
- **PAID: Pairwise Angular-Invariant Decomposition for Continual Test-Time Adaptation** (Accept (poster)) — Continual Test-Time Adaptation (CTTA) aims to online adapt a pre-trained model to changing environments during inference. Most existing methods focus on exploiting target data, while overlooking another crucial source… [OpenReview](https://openreview.net/forum?id=HWTdOSKK3n)
- **D2SA: Dual-Stage Distribution and Slice Adaptation for Efficient Test-Time Adaptation in MRI Reconstruction** (Accept (poster)) — Variations in Magnetic resonance imaging (MRI) scanners and acquisition protocols cause distribution shifts that degrade reconstruction performance on unseen data. Test-time adaptation (TTA) offers a promising solution… [OpenReview](https://openreview.net/forum?id=hyolWgWWyg)
- **Boosting Skeleton-based Zero-Shot Action Recognition with Training-Free Test-Time Adaptation** (Accept (poster)) — We introduce \textit{Skeleton-Cache}, the first training-free test-time adaptation framework for skeleton-based zero-shot action recognition (SZAR), aimed at improving model generalization to unseen actions during… [OpenReview](https://openreview.net/forum?id=wjXKFrUFzA)
- **Continual Gaussian Mixture Distribution Modeling for Class Incremental Semantic Segmentation** (Accept (poster)) — Class incremental semantic segmentation (CISS) enables a model to continually segment new classes from non-stationary data while preserving previously learned knowledge. Recent top-performing approaches are prototype-… [OpenReview](https://openreview.net/forum?id=dtYKDOBkc7)
- **MLRC-Bench: Can Language Agents Solve Machine Learning Research Challenges?** (Accept (poster)) — We introduce **MLRC-Bench**, a benchmark designed to quantify how effectively language agents can tackle challenging **M**achine **L**earning (ML) **R**esearch **C**ompetitions, with a focus on open research problems… [OpenReview](https://openreview.net/forum?id=t8Okk2PRWU)
- **InstructSAM: A Training-free Framework for Instruction-Oriented Remote Sensing Object Recognition** (Accept (poster)) — Language-Guided object recognition in remote sensing imagery is crucial for large-scale mapping and automated data annotation. However, existing open-vocabulary and visual grounding methods rely on explicit category… [OpenReview](https://openreview.net/forum?id=7yRwAEWxto)
- **REP: Resource-Efficient Prompting for Rehearsal-Free Continual Learning** (Accept (poster)) — Recent rehearsal-free continual learning (CL) methods guided by prompts achieve strong performance on vision tasks with non-stationary data but remain resource-intensive, hindering real-world deployment. We introduce… [OpenReview](https://openreview.net/forum?id=QjmRIgTcU8)
- **ARIA: Training Language Agents with Intention-driven Reward Aggregation** (Accept (spotlight)) — Large language models (LLMs) have enabled agents to perform complex reasoning and decision-making through free-form language interactions. However, in open-ended language action environments (e.g., negotiation or… [OpenReview](https://openreview.net/forum?id=eumRwpgdMU)
- **Bit-swapping Oriented Twin-memory Multi-view Clustering in Lifelong Incomplete Scenarios** (Accept (poster)) — Although receiving notable improvements, current multi-view clustering (MVC) techniques generally rely on feature library mechanisms to propagate accumulated knowledge from historical views to newly-arrived data, which… [OpenReview](https://openreview.net/forum?id=626icWM1xd)
- **UFO: A Unified Approach to Fine-grained Visual Perception via Open-ended Language Interface** (Accept (spotlight)) — Generalist models have achieved remarkable success in both language and vision-language tasks, showcasing the potential of unified modeling. However, effectively integrating fine-grained perception tasks like detection… [OpenReview](https://openreview.net/forum?id=8omLr8BtjL)
- **GraphChain: Large Language Models for Large-scale Graph Analysis via Tool Chaining** (Accept (poster)) — Large Language Models (LLMs) face significant limitations when applied to large-scale graphs, struggling with context constraints and inflexible reasoning. We introduce GraphChain, a novel framework enabling LLMs to… [OpenReview](https://openreview.net/forum?id=Rdz6ESQYkK)
- **Separating the 'what' and 'how' of compositional computation to enable reuse and continual learning** (Accept (poster)) — The ability to continually learn new skills, retain, and flexibly deploy them to accomplish goals is a key feature of intelligent and efficient behavior. However, the neural mechanisms facilitating the continual… [OpenReview](https://openreview.net/forum?id=Wg9gAqjAHb)
- **Test-Time Spectrum-Aware Latent Steering for Zero-Shot Generalization in Vision-Language Models** (Accept (poster)) — Vision–language models (VLMs) excel at zero-shot inference but often degrade under test-time domain shifts. For this reason, episodic test-time adaptation strategies have recently emerged as powerful techniques for… [OpenReview](https://openreview.net/forum?id=eV2Y8Gt6JY)
- **Class-wise Balancing Data Replay for Federated Class-Incremental Learning** (Accept (oral)) — Federated Class Incremental Learning (FCIL) aims to collaboratively process continuously increasing incoming tasks across multiple clients. Among various approaches, data replay has become a promising solution, which… [OpenReview](https://openreview.net/forum?id=aUAG1WS7J2)
- **Class-wise Balancing Data Replay for Federated Class-Incremental Learning** (Accept (oral)) — Federated Class Incremental Learning (FCIL) aims to collaboratively process continuously increasing incoming tasks across multiple clients. Among various approaches, data replay has become a promising solution, which… [OpenReview](https://openreview.net/forum?id=2025-Oral--11899-7e5aa2a8)
- **Task Similarity Matters: Greedy Orderings in Continual Linear Regression** (Accept (poster)) — We analyze task ordering strategies in continual learning for realizable linear regression.We focus on task orderings that greedily maximize dissimilarity between consecutive tasks, a concept briefly explored in prior… [OpenReview](https://openreview.net/forum?id=8JdPqAMpi4)
- **AtmosSci-Bench: Evaluating the Recent Advance of Large Language Model for Atmospheric Science** (Accept (poster)) — The rapid advancements in large language models (LLMs), particularly in their reasoning capabilities, hold transformative potential for addressing complex challenges in atmospheric science. However, leveraging LLMs… [OpenReview](https://openreview.net/forum?id=vDm8VWYYuX)
- **Temporal-Difference Variational Continual Learning** (Accept (poster)) — Machine Learning models in real-world applications must continuously learn new tasks to adapt to shifts in the data-generating distribution. Yet, for Continual Learning (CL), models often struggle to balance learning… [OpenReview](https://openreview.net/forum?id=9iYKXx5ieE)
- **Activation-Informed Merging of Large Language Models** (Accept (poster)) — Model merging, a method that combines the parameters and embeddings of multiple fine-tuned large language models (LLMs), offers a promising approach to enhance model performance across various tasks while maintaining… [OpenReview](https://openreview.net/forum?id=T4qJuQCFAK)
- **E-BATS: Efficient Backpropagation-Free Test-Time Adaptation for Speech Foundation Models** (Accept (poster)) — Speech Foundation Models encounter significant performance degradation when deployed in real-world scenarios involving acoustic domain shifts, such as background noise and speaker accents. Test-time adaptation (TTA) has… [OpenReview](https://openreview.net/forum?id=WwzurufeFN)
- **Memory-Integrated Reconfigurable Adapters: A Unified Framework for Settings with Multiple Tasks** (Accept (poster)) — Organisms constantly pivot between tasks such as evading predators, foraging, traversing rugged terrain, and socializing, often within milliseconds. Remarkably, they preserve knowledge of once-learned environments sans… [OpenReview](https://openreview.net/forum?id=hwEhsFLPh1)
- **Exploiting Task Relationships for Continual Learning Using Transferability-Aware Task Embeddings** (Accept (poster)) — Continual learning (CL) has been a critical topic in contemporary deep neural network applications, where higher levels of both forward and backward transfer are desirable for an effective CL performance. Existing CL… [OpenReview](https://openreview.net/forum?id=V8FnYzDX35)
- **LASeR: Learning to Adaptively Select Reward Models with Multi-Arm Bandits** (Accept (poster)) — Reward Models (RMs) are crucial to aligning large language models (LLMs), but the degree to which an RM specialized to one task (e.g. writing) generalizes to new tasks (e.g. math) is often not known a priori, often… [OpenReview](https://openreview.net/forum?id=tSpWkTFASC)
- **K-DeCore: Facilitating Knowledge Transfer in Continual Structured Knowledge Reasoning via Knowledge Decoupling** (Accept (poster)) — Continual Structured Knowledge Reasoning (CSKR) focuses on training models to handle sequential tasks, where each task involves translating natural language questions into structured queries grounded in structured… [OpenReview](https://openreview.net/forum?id=stiJen3iNI)
- **Align-DA: Align Score-based Atmospheric Data Assimilation with Multiple Preferences** (Accept (poster)) — Data assimilation (DA) aims to estimate the full state of a dynamical system by combining partial and noisy observations with a prior model forecast, commonly referred to as the background. In atmospheric applications,… [OpenReview](https://openreview.net/forum?id=EZAotKVWfk)
- **Measure gradients, not activations! Enhancing neuronal activity in deep reinforcement learning** (Accept (poster)) — Deep reinforcement learning (RL) agents frequently suffer from neuronal activity loss, which impairs their ability to adapt to new data and learn continually. A common method to quantify and address this issue is the… [OpenReview](https://openreview.net/forum?id=FjNHmO39pp)
- **Sparse Diffusion Autoencoder for Test-time Adapting Prediction of Spatiotemporal Dynamics** (Accept (poster)) — Predicting the behavior of complex systems is critical in many scientific and engineering domains, and hinges on the model’s ability to capture their underlying dynamics.Existing methods encode the intrinsic dynamics of… [OpenReview](https://openreview.net/forum?id=iWWPtwXfnO)
- **Unsupervised Post-Training for Multi-Modal LLM Reasoning via GRPO** (Accept (poster)) — Improving Multi-modal Large Language Models (MLLMs) in the post-training stage typically relies on supervised fine-tuning (SFT) or reinforcement learning (RL). However, these supervised methods require expensive and… [OpenReview](https://openreview.net/forum?id=HL1j92hb6z)
- **Compact Memory for Continual Logistic Regression** (Accept (poster)) — Despite recent progress, continual lifelong learning algorithms still do not match the performance of batch training. A major challenge is to represent old knowledge and reuse it to learn while avoiding forgetting. It… [OpenReview](https://openreview.net/forum?id=XLa5Puhqzg)
- **Recurrent Memory for Online Interdomain Gaussian Processes** (Accept (poster)) — We propose a novel online Gaussian process (GP) model that is capable of capturing long-term memory in sequential data in an online learning setting. Our model, Online HiPPO Sparse Variational Gaussian Process (OHSVGP),… [OpenReview](https://openreview.net/forum?id=BtPg90UEbw)
- **SimWorld: An Open-ended Simulator for Agents in Physical and Social Worlds** (Accept (spotlight)) — While LLM/VLM-powered AI agents have advanced rapidly in math, coding, and computer use, their applications in complex physical and social environments remain challenging. Building agents that can survive and thrive in… [OpenReview](https://openreview.net/forum?id=FxCy8TvQHO)
- **Rethinking Entropy in Test-Time Adaptation: The Missing Piece from Energy Duality** (Accept (spotlight)) — Test-time adaptation (TTA) aims to preserve model performance under distribution shifts. Yet, most existing methods rely on entropy minimization for confident predictions. This paper re-examines the sufficiency of… [OpenReview](https://openreview.net/forum?id=BKYFAutCDZ)
- **ReservoirTTA: Prolonged Test-time Adaptation for Evolving and Recurring Domains** (Accept (poster)) — This paper introduces **ReservoirTTA**, a novel plug–in framework designed for prolonged test–time adaptation (TTA) in scenarios where the test domain continuously shifts over time, including cases where domains recur… [OpenReview](https://openreview.net/forum?id=XewZ4rJYKZ)
- **Monitoring Risks in Test-Time Adaptation** (Accept (poster)) — Encountering shifted data at test time is a ubiquitous challenge when deploying predictive machine learning models. Test-time adaptation (TTA) methods aim to address this issue by continuously adapting a deployed model… [OpenReview](https://openreview.net/forum?id=TzHX2RWUdE)
- **Large Language Models Think Too Fast To Explore Effectively** (Accept (poster)) — Large Language Models (LLMs) have emerged with many intellectual capacities. While numerous benchmarks assess their intelligence, limited attention has been given to their ability to explore—an essential capacity for… [OpenReview](https://openreview.net/forum?id=jW8nBi6y9F)
- **FlexOLMo: Open Language Models for Flexible Data Use** (Accept (spotlight)) — We introduce FlexOLMo, a new class of language models (LMs) that supports (1) distributed training without data sharing, where different model parameters are independently trained on private datasets, and (2) data-… [OpenReview](https://openreview.net/forum?id=1rUj9ZN6Bz)
- **Contribution of task-irrelevant stimuli to drift of neural representations** (Accept (poster)) — Despite being observed in biological and artificial neural networks, mechanisms of representational drift are still under investigation. Under one set of hypotheses, drift is a result of noisy continual learning, which… [OpenReview](https://openreview.net/forum?id=jAoqtT58G4)
- **Abstract Counterfactuals for Language Model Agents** (Accept (poster)) — Counterfactual inference is a powerful tool for analysing and evaluating autonomous agents, but its application to language model (LM) agents remains challenging. Existing work on counterfactuals in LMs has primarily… [OpenReview](https://openreview.net/forum?id=ifMZw5fm7K)
- **Agnostic Continuous-Time Online Learning** (Accept (poster)) — We study agnostic online learning from continuous-time data streams, a setting that naturally arises in applications such as environmental monitoring, personalized recommendation, and high-frequency trading. Unlike… [OpenReview](https://openreview.net/forum?id=9LoVCfMLDl)
- **SciArena: An Open Evaluation Platform for Foundation Models in Scientific Literature Tasks** (Accept (spotlight)) — We present SciArena, an open and collaborative platform for evaluating foundation models on scientific literature tasks. Unlike traditional benchmarks for scientific literature understanding and synthesis, SciArena… [OpenReview](https://openreview.net/forum?id=am6RR85mnc)
- **Distribution-Aligned Decoding for Efficient LLM Task Adaptation** (Accept (poster)) — Adapting billion-parameter language models to a downstream task is still costly, even with parameter-efficient fine-tuning (PEFT). We re-cast task adaptation as output-distribution alignment: the objective is to steer… [OpenReview](https://openreview.net/forum?id=IVWHe60vfA)
- **OWMM-Agent: Open World Mobile Manipulation With Multi-modal Agentic Data Synthesis** (Accept (poster)) — The rapid progress of navigation, manipulation, and vision models has made mobile manipulators capable in many specialized tasks. However, the open-world mobile manipulation (OWMM) task remains a challenge due to the… [OpenReview](https://openreview.net/forum?id=vSLzoUoJt6)
- **Visual Instruction Bottleneck Tuning** (Accept (poster)) — Despite widespread adoption, multimodal large language models (MLLMs) suffer performance degradation when encountering unfamiliar queries under distribution shifts. Existing methods to improve MLLM generalization… [OpenReview](https://openreview.net/forum?id=yzHiEmLSk8)
- **CALM: Culturally Self-Aware Language Models** (Accept (poster)) — Cultural awareness in language models refers to the ability to understand norms, values, and perspectives embedded in diverse cultural contexts. However, existing approaches often treat culture as static background… [OpenReview](https://openreview.net/forum?id=16QYhVFvrO)
- **Turning the Tables: Enabling Backward Transfer via Causal-Aware LoRA in Continual Learning** (Accept (poster)) — Current parameter-efficient fine-tuning (PEFT) methods have shown superior performance in continual learning. However, most existing PEFT-based methods focus on mitigating catastrophic forgetting by limiting… [OpenReview](https://openreview.net/forum?id=bdGsKis3Ew)
- **Differential Privacy on Fully Dynamic Streams** (Accept (spotlight)) — A fundamental problem in differential privacy is to release privatized answers to a class of linear queries with small error. This problem has been well studied in the static case. In this paper, we consider the fully… [OpenReview](https://openreview.net/forum?id=piM21sPyVL)
- **Mitigating Intra- and Inter-modal Forgetting in Continual Learning of Unified Multimodal Models** (Accept (poster)) — Unified Multimodal Generative Models (UMGMs) unify visual understanding and image generation within a single autoregressive framework. However, their ability to continually learn new tasks is severely hindered by… [OpenReview](https://openreview.net/forum?id=CBsANtjBV4)
- **DOTA: Distributional Test-time Adaptation of Vision-Language Models** (Accept (poster)) — Vision-language foundation models (VLMs), such as CLIP, exhibit remarkable performance across a wide range of tasks. However, deploying these models can be unreliable when significant distribution gaps exist between… [OpenReview](https://openreview.net/forum?id=2T6QXSP8Cf)
- **Learn2Mix: Training Neural Networks Using Adaptive Data Integration** (Accept (poster)) — Accelerating model convergence in resource-constrained environments is essential for fast and efficient neural network training. This work presents learn2mix, a new training strategy that adaptively adjusts class… [OpenReview](https://openreview.net/forum?id=35Rum4a6tC)
- **A Controllable Examination for Long-Context Language Models** (Accept (spotlight)) — Existing frameworks for evaluating long-context language models (LCLM) can be broadly categorized into real-world and synthetic tasks.Despite their utility, both approaches are accompanied by certain intrinsic… [OpenReview](https://openreview.net/forum?id=atjpGqjG73)
- **Escaping Collapse: The Strength of Weak Data for Large Language Model Training** (Accept (poster)) — Synthetically-generated data plays an increasingly larger role in training large language models. However, while synthetic data has been found to be useful, studies have also shown that without proper curation it can… [OpenReview](https://openreview.net/forum?id=xpY3C8HxNh)
- **Training-Free Test-Time Adaptation via Shape and Style Guidance for Vision-Language Models** (Accept (poster)) — Test-time adaptation with pre-trained vision-language models shows impressive zero-shot classification abilities, and training-free methods further improve the performance without any optimization burden. However,… [OpenReview](https://openreview.net/forum?id=OF7OLxvY0t)
- **Test-Time Adaptation of Vision-Language Models for Open-Vocabulary Semantic Segmentation** (Accept (poster)) — Recently, test-time adaptation has attracted wide interest in the context of vision-language models for image classification. However, to the best of our knowledge, the problem is completely overlooked in dense… [OpenReview](https://openreview.net/forum?id=CH76rSKWZr)
- **TRUST: Test-Time Refinement using Uncertainty-Guided SSM Traverses** (Accept (poster)) — State Space Models (SSMs) have emerged as efficient alternatives to Vision Transformers (ViTs), with VMamba standing out as a pioneering architecture designed for vision tasks. However, their generalization performance… [OpenReview](https://openreview.net/forum?id=VewW9QYUA6)
- **Measuring Scientific Capabilities of Language Models with a Systems Biology Dry Lab** (Accept (poster)) — Designing experiments and result interpretations are core scientific competencies, particularly in biology, where researchers perturb complex systems to uncover the underlying systems. Recent efforts to evaluate the… [OpenReview](https://openreview.net/forum?id=Cmx6b7w2nk)
- **Benchmarking Egocentric Multimodal Goal Inference for Assistive Wearable Agents** (Accept (spotlight)) — There has recently been a surge of interest in Wearable Assistant Agents: agents embodied in a wearable form factor such as smart glasses, who can take actions toward a user’s stated goal — a high-level language-… [OpenReview](https://openreview.net/forum?id=REG4cJItSZ)
- **Partition-Then-Adapt: Combating Prediction Bias for Reliable Multi-Modal Test-Time Adaptation** (Accept (spotlight)) — Existing test-time adaptation (TTA) methods primarily focus on scenarios involving domain shifts in a single modality. However, they often prove ineffective when multiple modalities simultaneously undergo domain shifts,… [OpenReview](https://openreview.net/forum?id=T6RkYsuoMW)
- **ViSPLA: Visual Iterative Self-Prompting for Language-Guided 3D Affordance Learning** (Accept (poster)) — We address the problem of language-guided 3D affordance prediction, a core capability for embodied agents interacting with unstructured environments. Existing methods often rely on fixed affordance categories or require… [OpenReview](https://openreview.net/forum?id=EyNzLH7BZK)
- **$\texttt{AVROBUSTBENCH}$: Benchmarking the Robustness of Audio-Visual Recognition Models at Test-Time** (Accept (poster)) — While recent audio-visual models have demonstrated impressive performance, their robustness to distributional shifts at test-time remains not fully understood. Existing robustness benchmarks mainly focus on single… [OpenReview](https://openreview.net/forum?id=GiUI70epUN)
- **Hybrid Re-matching for Continual Learning with Parameter-Efficient Tuning** (Accept (poster)) — Continual learning seeks to enable a model to assimilate knowledge from non-stationary data streams without catastrophic forgetting. Recently, methods based on Parameter-Efficient Tuning (PET) have achieved superior… [OpenReview](https://openreview.net/forum?id=DCc4OyNX8A)
- **SimpleStrat: Addressing Language Model Coverage with Stratification** (Accept (poster)) — Generating diverse responses from large language models (LLMs) is crucial for applications such as planning/search and synthetic data generation, where diversity provides distinct answers across generations. Previous… [OpenReview](https://openreview.net/forum?id=X5B2yTT97A)
- **Feature-Based Instance Neighbor Discovery: Advanced Stable Test-Time Adaptation in Dynamic World** (Accept (poster)) — Despite progress, deep neural networks still suffer performance declines under distribution shifts between training and test domains, leading to a substantial decrease in Quality of Experience (QoE) for applications.… [OpenReview](https://openreview.net/forum?id=bLXfEMe1Dk)
- **Rare Text Semantics Were Always There in Your Diffusion Transformer** (Accept (poster)) — Starting from flow- and diffusion-based transformers, Multi-modal Diffusion Transformers (MM-DiTs) have reshaped text-to-vision generation, gaining acclaim for exceptional visual fidelity. As these models advance, users… [OpenReview](https://openreview.net/forum?id=tkV3n52mQO)
- **Fast Last-Iterate Convergence of SGD in the Smooth Interpolation Regime** (Accept (poster)) — We study population convergence guarantees of stochastic gradient descent (SGD) for smooth convex objectives in the interpolation (low noise) regime. The behavior of the last iterate of SGD in this setting---… [OpenReview](https://openreview.net/forum?id=ifGwVxiigF)
- **Optimal Rates in Continual Linear Regression via Increasing Regularization** (Accept (poster)) — We study realizable continual linear regression under random task orderings, a common setting for developing continual learning theory.In this setup, the worst-case expected loss after $k$ learning iterations admits a… [OpenReview](https://openreview.net/forum?id=lDh78hf5Vk)
- **CodeMerge: Codebook-Guided Model Merging for Robust Test-Time Adaptation in Autonomous Driving** (Accept (poster)) — Maintaining robust 3D perception under dynamic and unpredictable test-time conditions remains a critical challenge for autonomous driving systems. Existing test-time adaptation (TTA) methods often fail in high-variance… [OpenReview](https://openreview.net/forum?id=9eVXIN9Vij)
- **Knowledge Graph Enhanced Generative Multi-modal Models for Class-Incremental Learning** (Accept (poster)) — Continual learning in computer vision faces the critical challenge of catastrophic forgetting, where models struggle to retain prior knowledge while adapting to new tasks.Although recent studies have attempted to… [OpenReview](https://openreview.net/forum?id=SeC5Zb8Orf)
- **Towards Minimizing Feature Drift in Model Merging: Layer-wise Task Vector Fusion for Adaptive Knowledge Integration** (Accept (poster)) — Multi-task model merging aims to consolidate knowledge from multiple fine-tuned task-specific experts into a unified model while minimizing performance degradation. Existing methods primarily approach this by minimizing… [OpenReview](https://openreview.net/forum?id=0KOfAUiHua)
- **MOTION: Multi-Sculpt Evolutionary Coarsening for Federated Continual Graph Learning** (Accept (poster)) — Graph neural networks (GNNs) have achieved remarkable success in various domains but typically rely on centralized, static graphs, which limits their applicability in distributed, evolving environments. To address this… [OpenReview](https://openreview.net/forum?id=qmbG6u7DK0)
- **Dynam3D: Dynamic Layered 3D Tokens Empower VLM for Vision-and-Language Navigation** (Accept (oral)) — Vision-and-Language Navigation (VLN) is a core task where embodied agents leverage their spatial mobility to navigate in 3D environments toward designated destinations based on natural language instructions. Recently,… [OpenReview](https://openreview.net/forum?id=s6k9l5yX8e)
- **Towards Backpropagation-Free and Distribution-Aware Test-Time Adaptation** (Accept (poster)) — Test-time adaptation (TTA) enhances the zero-shot robustness under distribution shifts by leveraging unlabeled test data during inference. Despite notable advances, several challenges still limit its broader… [OpenReview](https://openreview.net/forum?id=rYv42fDKQi)
- **Dynam3D: Dynamic Layered 3D Tokens Empower VLM for Vision-and-Language Navigation** (Accept (oral)) — Vision-and-Language Navigation (VLN) is a core task where embodied agents leverage their spatial mobility to navigate in 3D environments toward designated destinations based on natural language instructions. Recently,… [OpenReview](https://openreview.net/forum?id=2025-Oral--7418-dd367268)
- **Hippocampal-like Sequential Editing for Continual Knowledge Updates in Large Language Models** (Accept (poster)) — Large language models (LLMs) are now pivotal in real-world applications. Model editing has emerged as a promising paradigm for efficiently modifying LLMs without full retraining. However, current editing approaches face… [OpenReview](https://openreview.net/forum?id=tqriGodQ79)
- **Resource-Constrained Federated Continual Learning: What Does Matter?** (Accept (poster)) — Federated Continual Learning (FCL) aims to enable sequential privacy-preserving model training on streams of incoming data that vary in edge devices by preserving previous knowledge while adapting to new data. Current… [OpenReview](https://openreview.net/forum?id=5aIVAGHCa5)
- **PointMAC: Meta-Learned Adaptation for Robust Test-Time Point Cloud Completion** (Accept (poster)) — Point cloud completion is essential for robust 3D perception in safety-critical applications such as robotics and augmented reality. However, existing models perform static inference and rely heavily on inductive biases… [OpenReview](https://openreview.net/forum?id=4xl00JWQ1z)
- **Efficient Low-Rank Model Merging in Core Space** (Accept (poster)) — In this paper we address the challenges associated with merging low-rank adaptations of large neural networks. With the rise of parameter-efficient adaptation techniques, such as Low-Rank Adaptation (LoRA), model fine-… [OpenReview](https://openreview.net/forum?id=y1z7SAS8q8)
- **AlgoTune: Can Language Models Speed Up General-Purpose Numerical Programs?** (Accept (poster)) — Despite progress in language model (LM) capabilities, evaluations have thus far focused on models' performance on tasks that humans have previously solved, including in programming (SWE-Bench) and mathematics… [OpenReview](https://openreview.net/forum?id=dF1tD9hjvn)
- **Bridging Human and LLM Judgments: Calibration, Alignment, and Bias Detection** (Accept (poster)) — LLM-as-a-judge (LLMJ) has become popular for scalably evaluating language model outputs on open-ended user queries. However, LLM judges do not always align with human annotators, exhibiting systematic and undesired… [OpenReview](https://openreview.net/forum?id=bEP87LNTfX)
- **Learning to Factorize Spatio-Temporal Foundation Models** (Accept (spotlight)) — Spatio-Temporal Foundation Models (STFMs) promise zero/few-shot generalization across various datasets, yet joint spatio-temporal pretraining is computationally prohibitive and struggles with domain-specific spatial… [OpenReview](https://openreview.net/forum?id=d4CZoiaXeC)
- **Dual-Space Semantic Synergy Distillation for Continual Learning of Unlabeled Streams** (Accept (poster)) — Continual learning from unlabeled data streams while effectively combating catastrophic forgetting poses an intractable challenge. Traditional methods predominantly rely on visual clustering techniques to generate… [OpenReview](https://openreview.net/forum?id=0g9gVoA7sn)
- **Train with Perturbation, Infer after Merging: A Two-Stage Framework for Continual Learning** (Accept (poster)) — Continual Learning (CL) aims to enable models to continuously acquire new knowledge from a sequence of tasks with avoiding the forgetting of learned information. However, existing CL methods only rely on the parameters… [OpenReview](https://openreview.net/forum?id=lqm1qJ43Sw)
- **Just attach! Buffer layers for Test-Time Adaptation** (Accept (poster)) — In recent advancements in Test Time Adaptation (TTA), most existing methodologies focus on updating normalization layers to adapt to the test domain. However, the reliance on normalization-based adaptation presents key… [OpenReview](https://openreview.net/forum?id=sSZ9OM08KT)
- **AutoRedTeamer: Autonomous Red Teaming with Lifelong Attack Integration** (Accept (poster)) — As large language models (LLMs) become increasingly capable, security and safety evaluation are crucial. While current red teaming approaches have made strides in assessing LLM vulnerabilities, they often rely heavily… [OpenReview](https://openreview.net/forum?id=xQH4lDLIC0)
- **MemEIC: A Step Toward Continual and Compositional Knowledge Editing** (Accept (poster)) — The dynamic nature of information necessitates continuously updating large vision-language models (LVLMs).While recent knowledge editing techniques hint at promising directions, they often focus on editing a single… [OpenReview](https://openreview.net/forum?id=Qvj8s2rRUs)
- **Private Continual Counting of Unbounded Streams** (Accept (poster)) — We study the problem of differentially private continual counting in the unbounded setting where the input size $n$ is not known in advance. Current state-of-the-art algorithms based on optimal instantiations of the… [OpenReview](https://openreview.net/forum?id=G8WnkCYEZ6)
- **Open-ended Scientific Discovery via Bayesian Surprise** (Accept (poster)) — The promise of autonomous scientific discovery (ASD) hinges not only on answering questions, but also on knowing which questions to ask. Most recent works in ASD explore the use of large language models (LLMs) in goal-… [OpenReview](https://openreview.net/forum?id=kJqTkj2HhF)
- **Stay True to the Evidence: Measuring Belief Entrenchment in Reasoning LLMs via the Martingale Property** (Accept (poster)) — Recent advances in reasoning techniques have substantially improved the performance of large language models (LLMs), raising expectations for their ability to provide accurate, truthful, and reliable information.… [OpenReview](https://openreview.net/forum?id=BfO6od6JD6)
- **Auto-Compressing Networks** (Accept (oral)) — Deep neural networks with short residual connections have demonstrated remarkable success across domains, but increasing depth often introduces computational redundancy without corresponding improvements in… [OpenReview](https://openreview.net/forum?id=2025-Oral--16200-c55388f7)
- **Auto-Compressing Networks** (Accept (oral)) — Deep neural networks with short residual connections have demonstrated remarkable success across domains, but increasing depth often introduces computational redundancy without corresponding improvements in… [OpenReview](https://openreview.net/forum?id=eIDa6pd9iQ)
- **Differentially Private Quantiles with Smaller Error** (Accept (poster)) — In the approximate quantiles problem, the goal is to output $m$ quantile estimates, the ranks of which are as close as possible to $m$ given quantiles $q_1,\dots,q_m$. We present a mechanism for approximate quantiles… [OpenReview](https://openreview.net/forum?id=y3Q3nod80m)
- **Learn and Ensemble Bridge Adapters for Multi-domain Task Incremental Learning** (Accept (poster)) — Multi-domain task incremental learning (MTIL) demands models to master domain-specific expertise while preserving generalization capabilities. Inspired by human lifelong learning, which relies on revisiting, aligning,… [OpenReview](https://openreview.net/forum?id=Cx6Kqto5h1)
- **Synthesizing Photorealistic and Dynamic Urban Environments for Multimodal Robot Navigation and Collaboration** (Accept (poster)) — Recent advances in foundation models have shown promising results in developing generalist robotics that can perform diverse tasks in open-ended scenarios given multimodal inputs. However, current work has been mainly… [OpenReview](https://openreview.net/forum?id=EyOtIOmMUh)
- **Continual Release Moment Estimation with Differential Privacy** (Accept (poster)) — We propose *Joint Moment Estimation* (JME), a method for continually and privately estimating both the first and second moments of a data stream with reduced noise compared to naive approaches. JME supports the *matrix… [OpenReview](https://openreview.net/forum?id=TXHc1gEEIk)
- **SPACE: SPike-Aware Consistency Enhancement for Test-Time Adaptation in Spiking Neural Networks** (Accept (poster)) — Spiking Neural Networks (SNNs), as a biologically plausible alternative to Artificial Neural Networks (ANNs), have demonstrated advantages in terms of energy efficiency, temporal processing, and biological plausibility.… [OpenReview](https://openreview.net/forum?id=Di0RasgbQ6)
- **Tackling Continual Offline RL through Selective Weights Activation on Aligned Spaces** (Accept (poster)) — Continual offline reinforcement learning (CORL) has shown impressive ability in diffusion-based continual learning systems by modeling the joint distributions of trajectories. However, most research only focuses on… [OpenReview](https://openreview.net/forum?id=KfRfTAJpjh)
- **The World Is Bigger: A Computationally-Embedded Perspective on the Big World Hypothesis** (Accept (spotlight)) — Continual learning is often motivated by the idea, known as the big world hypothesis, that the "world is bigger" than the agent. Recent problem formulations capture this idea by explicitly constraining an agent relative… [OpenReview](https://openreview.net/forum?id=gJclyLFSdU)
- **Federated Continual Learning via Orchestrating Multi-Scale Expertise** (Accept (poster)) — Federated continual learning (FCL) aims to maintain the model's performance on old tasks (i.e., stability) while enhancing its ability to acquire knowledge from current tasks (i.e., plasticity). With the development of… [OpenReview](https://openreview.net/forum?id=AlSHcopwHi)
- **DevFD : Developmental Face Forgery Detection by Learning Shared and Orthogonal LoRA Subspaces** (Accept (poster)) — The rise of realistic digital face generation/manipulation poses significant social risks. The primary challenge lies in the rapid and diverse evolution of generation techniques, which often outstrip the detection… [OpenReview](https://openreview.net/forum?id=Xpuci4SV06)
- **C-NAV: Continual Object Navigation with Dual-Path Anti-Forgetting and Adaptive Experience Selection** (Accept (poster)) — Embodied agents are expected to perform object navigation in dynamic, open-world environments. However, existing approaches typically rely on static trajectories and a fixed set of object categories during training,… [OpenReview](https://openreview.net/forum?id=SbfdxWibDn)
- **BackdoorLLM: A Comprehensive Benchmark for Backdoor Attacks and Defenses on Large Language Models** (Accept (poster)) — Generative large language models (LLMs) have achieved state-of-the-art results on a wide range of tasks, yet they remain susceptible to backdoor attacks: carefully crafted triggers in the input can manipulate the model… [OpenReview](https://openreview.net/forum?id=sYLiY87mNn)
- **A Spectral Understanding of LoRA Fine-Tuning** (Accept (poster)) — Fine-tuning is a crucial paradigm for adapting pre-trained large language models to downstream tasks. Recently, methods like Low-Rank Adaptation (LoRA) have been shown to effectively fine-tune LLMs with an extreme… [OpenReview](https://openreview.net/forum?id=xp7B8rkh7L)
- **Rethinking Hebbian Principle: Low-Dimensional Structural Projection for Unsupervised Learning** (Accept (poster)) — Hebbian learning is a biological principle that intuitively describes how neurons adapt connections through repeated stimuli. However, when applied to machine learning, it suffers serious issues due to the unconstrained… [OpenReview](https://openreview.net/forum?id=pm4Bl3D6XF)
- **Statistics Caching Test-Time Adaptation for Vision-Language Models** (Accept (poster)) — Test-time adaptation (TTA) for Vision-Language Models (VLMs) aims to enhance performance on unseen test data. However, existing methods struggle to achieve robust and continuous knowledge accumulation during test time.… [OpenReview](https://openreview.net/forum?id=iqsjzVqmWF)
- **RealMath: A Continuous Benchmark for Evaluating Language Models on Research-Level Mathematics** (Accept (poster)) — Existing benchmarks for evaluating mathematical reasoning in large language models (LLMs) rely primarily on competition problems, formal proofs, or artificially challenging questions---failing to capture the nature of… [OpenReview](https://openreview.net/forum?id=RBssYVpQEr)
- **SPICED: A Synaptic Homeostasis-Inspired Framework for Unsupervised Continual EEG Decoding** (Accept (poster)) — Human brain achieves dynamic stability-plasticity balance through synaptic homeostasis, a self-regulatory mechanism that stabilizes critical memory traces while preserving optimal learning capacities. Inspired by this… [OpenReview](https://openreview.net/forum?id=qcdoHkkHcb)
- **Fantastic Features and Where to Find Them: A Probing Method to combine Features from Multiple Foundation Models** (Accept (poster)) — Foundation models (FMs) trained with different objectives and data learn diverse representations, making some more effective than others for specific downstream tasks. Existing adaptation strategies – such as parameter-… [OpenReview](https://openreview.net/forum?id=PxgIElCohI)
- **Analytical Contrastive Projection for Accurate Continual Learning** (Accept (spotlight)) — This paper studies the class-incremental learning (CIL) setting of continual learning. CIL aims to learn a sequence of tasks, where each task consists of a set of classes. Traditional CIL methods does not use a pre-… [OpenReview](https://openreview.net/forum?id=qQbvLU34F1)
- **Reliable Lifelong Multimodal Editing: Conflict-Aware Retrieval Meets Multi-Level Guidance** (Accept (poster)) — The dynamic nature of real-world information demands efficient knowledge editing in multimodal large language models (MLLMs) to ensure continuous knowledge updates. However, existing methods often struggle with precise… [OpenReview](https://openreview.net/forum?id=hdJXzKZjY9)
- **ADMN: A Layer-Wise Adaptive Multimodal Network for Dynamic Input Noise and Compute Resources** (Accept (poster)) — Multimodal deep learning systems are deployed in dynamic scenarios due to the robustness afforded by multiple sensing modalities. Nevertheless, they struggle with varying compute resource availability (due to multi-… [OpenReview](https://openreview.net/forum?id=q1W0O5p1w1)
- **OPMapper: Enhancing Open-Vocabulary Semantic Segmentation with Multi-Guidance Information** (Accept (poster)) — Open-vocabulary semantic segmentation assigns every pixel a label drawn from an open-ended, text-defined space. Vision–language models such as CLIP excel at zero-shot recognition, yet their image-level pre-training… [OpenReview](https://openreview.net/forum?id=UjSBOwKZ02)
- **MergeBench: A Benchmark for Merging Domain-Specialized LLMs** (Accept (poster)) — Model merging provides a scalable alternative to multi-task training by combining specialized finetuned models through parameter arithmetic, enabling efficient deployment without the need for joint training or access to… [OpenReview](https://openreview.net/forum?id=rw50iUoyLu)
- **Parameter Dynamics of Online Machine Learning and Test-time Adaptation** (Accept (poster)) — Foundation models based on deep neural networks hold strong potential for cross-domain adaptability. However, this potential is often impeded in online machine learning (OML) settings, where the breakdown of the… [OpenReview](https://openreview.net/forum?id=pdlepT2alu)
- **Edit Less, Achieve More: Dynamic Sparse Neuron Masking for Lifelong Knowledge Editing in LLMs** (Accept (poster)) — Lifelong knowledge editing enables continuous, precise updates to outdated knowledge in large language models (LLMs) without computationally expensive full retraining. However, existing methods often accumulate errors… [OpenReview](https://openreview.net/forum?id=feAzLLT9to)
- **BMMR: A Large-Scale Bilingual Multimodal Multi-Discipline Reasoning Dataset** (Accept (poster)) — In this paper, we introduce BMMR, a large-scale bilingual, multimodal, multi-disciplinary reasoning dataset for the community to develop and evaluate large multimodal models (LMMs). BMMR comprises 100k university-level… [OpenReview](https://openreview.net/forum?id=2XstFOMwp4)
- **What do you know? Bayesian knowledge inference for navigating agents** (Accept (poster)) — Human behavior is characterized by continuous learning to reduce uncertainties about the world in pursuit of goals. When trying to understand such behavior from observations, it is essential to account for this adaptive… [OpenReview](https://openreview.net/forum?id=rqXEiXZT6C)
- **MLE-Dojo: Interactive Environments for Empowering LLM Agents in Machine Learning Engineering** (Accept (poster)) — We introduce MLE-Dojo, a Gym-style framework for systematically reinforcement learning, evaluating, and improving autonomous large language model (LLM) agents in iterative machine learning engineering (MLE) workflows.… [OpenReview](https://openreview.net/forum?id=5W5mFU4oMO)
- **MLR-Bench: Evaluating AI Agents on Open-Ended Machine Learning Research** (Accept (poster)) — Recent advancements in AI agents have demonstrated their growing potential to drive and support scientific discovery. In this work, we introduce \textbf{MLR-Bench}, a comprehensive benchmark for evaluating AI agents on… [OpenReview](https://openreview.net/forum?id=JX9DE6colf)
- **CaMiT: A Time-Aware Car Model Dataset for Classification and Generation** (Accept (poster)) — AI systems must adapt to the evolving visual landscape, especially in domains where object appearance shifts over time. While prior work on time-aware vision models has primarily addressed commonsense-level categories,… [OpenReview](https://openreview.net/forum?id=VfG4FBJ9Gc)
- **MEMOIR: Lifelong Model Editing with Minimal Overwrite and Informed Retention for LLMs** (Accept (poster)) — Language models deployed in real-world systems often require post-hoc updates to incorporate new or corrected knowledge. However, editing such models efficiently and reliably—without retraining or forgetting previous… [OpenReview](https://openreview.net/forum?id=t94tALZvZE)
- **Top-H Decoding: Adapting the Creativity and Coherence with Bounded Entropy in Text Generation** (Accept (poster)) — Large language models (LLMs), despite their impressive performance across a wide range of tasks, often struggle to balance two competing objectives in open-ended text generation: fostering diversity and creativity while… [OpenReview](https://openreview.net/forum?id=3G0IWDIoRG)
- **DAA: Amplifying Unknown Discrepancy for Test-Time Discovery** (Accept (poster)) — Test-Time Discovery (TTD) addresses the critical challenge of identifying and adapting to novel classes during inference while maintaining performance on known classes, which is a capability essential for dynamic real-… [OpenReview](https://openreview.net/forum?id=gVKxz6M1ov)
- **Evolving and Regularizing Meta-Environment Learner for Fine-Grained Few-Shot Class-Incremental Learning** (Accept (poster)) — Recently proposed Fine-Grained Few-Shot Class-Incremental Learning (FG-FSCIL) offers a practical and efficient solution for enabling models to incrementally learn new fine-grained categories under limited data… [OpenReview](https://openreview.net/forum?id=AU2eaY2QEu)
- **HM3: Hierarchical Multi-Objective Model Merging for Pretrained Models** (Accept (spotlight)) — Model merging is a technique that combines multiple large pretrained models into a single model, enhancing performance and broadening task adaptability without original data or additional training. However, most… [OpenReview](https://openreview.net/forum?id=JeP0lpusYw)
- **Fast and Fluent Diffusion Language Models via Convolutional Decoding and Rejective Fine-tuning** (Accept (spotlight)) — Autoregressive (AR) language models generate text one token at a time, which limits their inference speed. Diffusion-based language models offer a promising alternative, as they can decode multiple tokens in parallel.… [OpenReview](https://openreview.net/forum?id=HvIRFV0J90)
- **Contrastive Consolidation of Top-Down Modulations Achieves Sparsely Supervised Continual Learning** (Accept (poster)) — Biological brains learn continually from a stream of unlabeled data, while integrating specialized information from sparsely labeled examples without compromising their ability to generalize.Meanwhile, machine learning… [OpenReview](https://openreview.net/forum?id=pLDpenGIjl)
- **MindForge: Empowering Embodied Agents with Theory of Mind for Lifelong Cultural Learning** (Accept (poster)) — Embodied agents powered by large language models (LLMs), such as Voyager, promise open-ended competence in worlds such as Minecraft. However, when powered by open-weight LLMs they still falter on elementary tasks after… [OpenReview](https://openreview.net/forum?id=u7jtLj46i9)
- **CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation** (Accept (poster)) — Vision-language models (VLMs) like CLIP exhibit strong zero-shot capabilities but often fail to generalize under distribution shifts. Test-time adaptation (TTA) allows models to update at inference time without labeled… [OpenReview](https://openreview.net/forum?id=w9gEF4Iwtx)
- **AI-Researcher: Autonomous Scientific Innovation** (Accept (spotlight)) — The powerful reasoning capabilities of Large Language Models (LLMs) in mathematics and coding, combined with their ability to automate complex tasks through agentic frameworks, present unprecedented opportunities for… [OpenReview](https://openreview.net/forum?id=kQWyOYUAC4)
- **On Evaluating LLM Alignment by Evaluating LLMs as Judges** (Accept (poster)) — Evaluating large language models' (LLMs) alignment with human preferences typically involves directly assessing their open-ended responses, requiring human annotators or strong LLM judges. Conversely, LLMs themselves… [OpenReview](https://openreview.net/forum?id=OBaK9JSbHk)
- **An Evidence-Based Post-Hoc Adjustment Framework for Anomaly Detection Under Data Contamination** (Accept (spotlight)) — Unsupervised anomaly detection (AD) methods typically assume clean training data, yet real-world datasets often contain undetected or mislabeled anomalies, leading to significant performance degradation. Existing… [OpenReview](https://openreview.net/forum?id=NgLFQTBPRR)
- **RobIA: Robust Instance-aware Continual Test-time Adaptation for Deep Stereo** (Accept (poster)) — Stereo Depth Estimation in real-world environments poses significant challenges due to dynamic domain shifts, sparse or unreliable supervision, and the high cost of acquiring dense ground-truth labels. While recent… [OpenReview](https://openreview.net/forum?id=LqgRi1avf5)
- **VL-SAM-V2: Open-World Object Detection with General and Specific Query Fusion** (Accept (poster)) — Current perception models have achieved remarkable success by leveraging large-scale labeled datasets, but still face challenges in open-world environments with novel objects. To address this limitation, researchers… [OpenReview](https://openreview.net/forum?id=KoCytqC9gx)
- **Searching Latent Program Spaces** (Accept (spotlight)) — General intelligence requires systems that acquire new skills efficiently and generalize beyond their training distributions.Although program synthesis approaches have strong generalization power, they face scaling… [OpenReview](https://openreview.net/forum?id=CsXKGIqZtr)
- **DeepDiver: Adaptive Web-Search Intensity Scaling via Reinforcement Learning** (Accept (spotlight)) — Information seeking demands iterative evidence gathering and reflective reasoning, yet large language models (LLMs) still struggle with it in open-web question answering. Existing prompting and supervised fine-tuning… [OpenReview](https://openreview.net/forum?id=CqLWckpTbG)
- **COLA: Towards Efficient Multi-Objective Reinforcement Learning with Conflict Objective Regularization in Latent Space** (Accept (poster)) — Many real-world control problems require continual policy adjustments to balance multiple objectives, which requires the acquisition of high-quality policies to cover diverse preferences. Multi-Objective Reinforcement… [OpenReview](https://openreview.net/forum?id=Cldpn7H3NN)
- **LILO: Learning to Reason at the Frontier of Learnability** (Accept (poster)) — Reinforcement learning is widely adopted in post-training large language models, especially for reasoning-style tasks such as maths questions. However, as we show, most existing methods will provably fail to learn from… [OpenReview](https://openreview.net/forum?id=8HYeWMf0W3)
- **A Multimodal BiMamba Network with Test-Time Adaptation for Emotion Recognition Based on Physiological Signals** (Accept (poster)) — Emotion recognition based on physiological signals is of considerable significance in fields including psychological health and human-computer interaction, particularly in light of the substantial advances in multimodal… [OpenReview](https://openreview.net/forum?id=3vLp3J7540)
- **Looking Beyond the Known: Towards a Data Discovery Guided Open-World Object Detection** (Accept (poster)) — Open-World Object Detection (OWOD) enriches traditional object detectors by enabling continual discovery and integration of unknown objects via human guidance. However, existing OWOD approaches frequently suffer from… [OpenReview](https://openreview.net/forum?id=2tqcROH3iO)
- **Test-Time Adaptation by Causal Trimming** (Accept (poster)) — Test-time adaptation aims to improve model robustness under distribution shifts by adapting models with access to unlabeled target samples. A primary cause of performance degradation under such shifts is the model’s… [OpenReview](https://openreview.net/forum?id=zFGdHL9pcD)
- **Model Merging in Pre-training of Large Language Models** (Accept (poster)) — Model merging has emerged as a promising technique for enhancing large language models, though its application in large-scale pre-training remains relatively unexplored. In this paper, we present a comprehensive… [OpenReview](https://openreview.net/forum?id=HW55AwGEC8)
- **Class-aware Domain Knowledge Fusion and Fission for Continual Test-Time Adaptation** (Accept (poster)) — Continual Test-Time Adaptation (CTTA) aims to quickly fine-tune the model during the test phase so that it can adapt to multiple unknown downstream domain distributions without pre-acquiring downstream domain data. To… [OpenReview](https://openreview.net/forum?id=F74FXkicGK)
- **The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models** (Accept (poster)) — Test-time adaptation (TTA) methods have gained significant attention for enhancing the performance of vision-language models (VLMs) such as CLIP during inference, without requiring additional labeled data. However,… [OpenReview](https://openreview.net/forum?id=EVzjqVxOVS)
- **Continual Optimization with Symmetry Teleportation for Multi-Task Learning** (Accept (poster)) — Multi-task learning (MTL) is a widely explored paradigm that enables the simultaneous learning of multiple tasks using a single model. Despite numerous solutions, the key issues of optimization conflict and task… [OpenReview](https://openreview.net/forum?id=8P5MUySaqi)
- **OpenWorldSAM: Extending SAM2 for Universal Image Segmentation with Language Prompts** (Accept (spotlight)) — The ability to segment objects based on open-ended language prompts remains a critical challenge, requiring models to ground textual semantics into precise spatial masks while handling diverse and unseen categories. We… [OpenReview](https://openreview.net/forum?id=fLx3vQPmDu)
- **Decentralized Dynamic Cooperation of Personalized Models for Federated Continual Learning** (Accept (poster)) — Federated continual learning (FCL) has garnered increasing attention for its ability to support distributed computation in environments with evolving data distributions. However, the emergence of new tasks introduce… [OpenReview](https://openreview.net/forum?id=16BGOheRzm)
- **Scalable Best-of-N Selection for Large Language Models via Self-Certainty** (Accept (poster)) — Best-of-N selection is a key technique for improving the reasoning performance of Large Language Models (LLMs) through increased test-time computation. Current state-of-the-art methods often employ computationally… [OpenReview](https://openreview.net/forum?id=29FRqmVQK8)
- **Bisecle: Binding and Separation in Continual Learning for Video Language Understanding** (Accept (poster)) — Frontier vision-language models (VLMs) have made remarkable improvements in video understanding tasks. However, real-world videos typically exist as continuously evolving data streams (e.g., dynamic scenes captured by… [OpenReview](https://openreview.net/forum?id=o6keqobP13)

## Gradient-Free or Forward-Only LLM Fine-Tuning

- **Brain network science modelling of sparse neural networks enables Transformers and LLMs to perform as fully connected** (Accept (poster)) — This study aims to enlarge our current knowledge on the application of brain-inspired network science principles for training artificial neural networks (ANNs) with sparse connectivity. Dynamic sparse training (DST)… [OpenReview](https://openreview.net/forum?id=OM0Qkq9xtY)
- **PZO: Pseudo-Zeroth-Order Algorithm for Training Deep Neural Networks** (Accept (poster)) — Zeroth-order Optimization (ZO) has received wide attention in machine learning, especially when computing full gradient is expensive or even impossible. Recently, ZO has emerged as an important paradigm for memory-… [OpenReview](https://openreview.net/forum?id=tM4cHBD7kD)
- **Breaking the Gradient Barrier: Unveiling Large Language Models for Strategic Classification** (Accept (poster)) — Strategic classification (SC) explores how individuals or entities modify their features strategically to achieve favorable classification outcomes. However, existing SC methods, which are largely based on linear models… [OpenReview](https://openreview.net/forum?id=V0lnRCH73U)
- **Harmony in Divergence: Towards Fast, Accurate, and Memory-efficient Zeroth-order LLM Fine-tuning** (Accept (poster)) — Large language models (LLMs) excel across various tasks, but standard first-order (FO) fine-tuning demands considerable memory, significantly limiting real-world deployment. Recently, zeroth-order (ZO) optimization… [OpenReview](https://openreview.net/forum?id=Rx6m16By6l)
- **SECA: Semantically Equivalent & Coherent Attacks for Eliciting LLM Hallucinations** (Accept (poster)) — Large Language Models (LLMs) are increasingly deployed in high-risk domains where trustworthy outputs are essential. Despite their strong performance, state-of-the-art LLMs can still produce hallucinations, raising… [OpenReview](https://openreview.net/forum?id=8Flpo0zaaO)
- **PaZO: Preconditioned Accelerated Zeroth-Order Optimization for Fine-Tuning LLMs** (Accept (poster)) — This paper introduces PaZO, a preconditioned accelerated zeroth-order optimization algorithm for fine-tuning large language models (LLMs). First, we theoretically demonstrate the necessity of preconditioning in zeroth-… [OpenReview](https://openreview.net/forum?id=b2IU6QOOfo)
- **Bilevel ZOFO: Efficient LLM Fine-Tuning and Meta-Training** (Accept (poster)) — Fine-tuning pre-trained Large Language Models (LLMs) for downstream tasks using First-Order (FO) optimizers presents significant computational challenges. Parameter-Efficient Fine-Tuning~(PEFT) methods have been… [OpenReview](https://openreview.net/forum?id=v6vBK4t8vB)
- **Sparse MeZO: Less Parameters for Better Performance in Zeroth-Order LLM Fine-Tuning** (Accept (poster)) — While fine-tuning large language models (LLMs) for specific tasks often yields impressive results, it comes at the cost of memory inefficiency due to back-propagation in gradient-based training. Memory-efficient Zeroth-… [OpenReview](https://openreview.net/forum?id=Tjw0ACu3NL)